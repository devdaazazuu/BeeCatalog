# üöÄ Guia Completo de Migra√ß√£o e Otimiza√ß√£o - BeeCatalog

## üìã Diagn√≥stico Inicial

Este guia consolida todas as otimiza√ß√µes implementadas no BeeCatalog, incluindo:
- ‚úÖ Migra√ß√£o SQLite ‚Üí PostgreSQL com connection pooling
- ‚úÖ Sistema de cache inteligente Redis + Django-Redis
- ‚úÖ Processamento em lote otimizado para IA
- ‚úÖ Monitoramento com Prometheus + Grafana
- ‚úÖ Observabilidade com Sentry + logs estruturados
- ‚úÖ Otimiza√ß√µes Celery com filas dedicadas

## üéØ Plano de Execu√ß√£o

### Fase 1: Prepara√ß√£o e Backup

#### 1.1 Backup dos Dados Atuais
```bash
# Execute o backup do SQLite
python backup_sqlite.py

# Verificar se o backup foi criado
ls backup_*/
```

#### 1.2 Instala√ß√£o das Depend√™ncias
```bash
# Instalar novas depend√™ncias
pip install -r requirements.txt

# Verificar instala√ß√£o
pip list | grep -E "psycopg2|redis|sentry|prometheus"
```

### Fase 2: Configura√ß√£o da Infraestrutura

#### 2.1 Iniciar Servi√ßos com Docker
```bash
# Iniciar PostgreSQL, Redis e ferramentas de monitoramento
docker-compose up -d postgres redis prometheus grafana

# Verificar status dos servi√ßos
docker-compose ps
```

#### 2.2 Configurar Vari√°veis de Ambiente
```bash
# Adicionar ao .env
DATABASE_URL=postgresql://beecatalog_user:beecatalog_password@localhost:5432/beecatalog
REDIS_URL=redis://localhost:6379/0
SENTRY_DSN=your_sentry_dsn_here
DJANGO_SETTINGS_MODULE=backbeecatalog.settings
```

### Fase 3: Migra√ß√£o do Banco de Dados

#### 3.1 Executar Migra√ß√£o Automatizada
```bash
# Executar script de migra√ß√£o completo
python migrate_to_postgresql.py
```

#### 3.2 Restaurar Dados do Backup
```bash
# Carregar dados do backup
cd backup_YYYYMMDD_HHMMSS/
python restore_backup.py
```

#### 3.3 Verificar Integridade
```bash
# Verificar dados migrados
python manage.py shell
>>> from django.contrib.auth.models import User
>>> print(f"Usu√°rios: {User.objects.count()}")
>>> # Verificar outras tabelas importantes
```

### Fase 4: Configura√ß√£o do Celery Otimizado

#### 4.1 Iniciar Workers Especializados
```bash
# Terminal 1: Worker para planilhas (CPU intensivo)
celery -A backbeecatalog worker -Q spreadsheet --concurrency=4 --loglevel=info

# Terminal 2: Worker para scraping (I/O intensivo)
celery -A backbeecatalog worker -Q scraping --concurrency=2 --loglevel=info

# Terminal 3: Worker para IA (balanceado)
celery -A backbeecatalog worker -Q ai --concurrency=3 --loglevel=info

# Terminal 4: Flower para monitoramento
celery -A backbeecatalog flower --port=5555
```

#### 4.2 Verificar Filas
```bash
# Verificar status das filas
celery -A backbeecatalog inspect active_queues
```

### Fase 5: Teste das Otimiza√ß√µes

#### 5.1 Teste do Cache Inteligente
```python
# No Django shell
from api.cache_utils import get_or_cache_ai_response, get_cache_stats

# Testar cache
result = get_or_cache_ai_response(
    "test_prompt",
    lambda: "test_response",
    {"context": "test"},
    cache_ttl=300
)

# Verificar estat√≠sticas
stats = get_cache_stats()
print(f"Cache stats: {stats}")
```

#### 5.2 Teste do Processamento em Lote
```python
# Testar nova task otimizada
from api.tasks import optimized_generate_spreadsheet_task

# Executar task otimizada
result = optimized_generate_spreadsheet_task.delay(
    produtos_data=[...],  # seus dados de teste
    user_id=1
)

print(f"Task ID: {result.id}")
```

## üîß Entrega: Arquivos de Configura√ß√£o

### Arquivos Criados/Modificados:

1. **requirements.txt** - Depend√™ncias otimizadas
2. **settings.py** - Configura√ß√µes PostgreSQL, Redis, Sentry, Prometheus
3. **celery.py** - Configura√ß√µes otimizadas com filas dedicadas
4. **api/cache_utils.py** - Sistema de cache inteligente
5. **api/utils.py** - Fun√ß√µes IA otimizadas com cache
6. **api/tasks.py** - Tasks em lote otimizadas
7. **docker-compose.yml** - Infraestrutura completa
8. **migrate_to_postgresql.py** - Script de migra√ß√£o
9. **backup_sqlite.py** - Script de backup

### Configura√ß√µes de Monitoramento:

10. **prometheus.yml** - Configura√ß√£o de m√©tricas
11. **redis.conf** - Redis otimizado
12. **pgbouncer.ini** - Connection pooling
13. **beecatalog_rules.yml** - Alertas Prometheus

## ‚ö° Otimiza√ß√µes Implementadas

### 1. Performance de Banco de Dados
- **PostgreSQL** com connection pooling via PgBouncer
- **√çndices otimizados** para consultas frequentes
- **Configura√ß√µes de mem√≥ria** ajustadas para workload

### 2. Sistema de Cache Inteligente
- **Cache em duas camadas**: Django (r√°pido) + Redis (persistente)
- **Cache de respostas IA** com hash SHA256 de prompts
- **Invalida√ß√£o autom√°tica** e estat√≠sticas de hit rate
- **Processamento em lote** para m√∫ltiplas requisi√ß√µes IA

### 3. Otimiza√ß√µes Celery
- **Filas dedicadas** por tipo de workload:
  - `spreadsheet`: CPU intensivo (4 workers)
  - `scraping`: I/O intensivo (2 workers)
  - `ai`: Balanceado (3 workers)
- **Configura√ß√µes de performance**: prefetch, compression, retry
- **Logs estruturados** para debugging

### 4. Monitoramento e Observabilidade
- **Prometheus**: Coleta de m√©tricas
- **Grafana**: Dashboards visuais
- **Sentry**: Tracking de erros
- **Flower**: Monitoramento Celery
- **Logs estruturados**: JSON format para an√°lise

## üîç Pr√≥ximos Passos

### Monitoramento Cont√≠nuo
1. **Acessar Dashboards**:
   - Grafana: http://localhost:3000 (admin/admin123)
   - Prometheus: http://localhost:9090
   - Flower: http://localhost:5555

2. **Configurar Alertas**:
   - Configurar notifica√ß√µes Slack/Email no Grafana
   - Ajustar thresholds de alerta conforme necess√°rio

### Otimiza√ß√µes Futuras
1. **Scaling Horizontal**:
   - Configurar m√∫ltiplas inst√¢ncias Celery
   - Implementar load balancer

2. **Cache Avan√ßado**:
   - Implementar cache de resultados de scraping
   - Cache de embeddings para busca sem√¢ntica

3. **IA Otimizada**:
   - Implementar rate limiting inteligente
   - Cache de modelos pr√©-treinados
   - Batch processing para embeddings

### Manuten√ß√£o
1. **Backup Autom√°tico**:
   - Configurar backup di√°rio PostgreSQL
   - Rota√ß√£o de logs Redis

2. **Monitoramento de Recursos**:
   - Alertas de uso de mem√≥ria/CPU
   - Monitoramento de espa√ßo em disco

## üìä M√©tricas de Sucesso

### Performance Esperada
- **Redu√ß√£o de 60-80%** no tempo de gera√ß√£o de planilhas
- **Cache hit rate > 70%** para requisi√ß√µes IA
- **Throughput 3-5x maior** para processamento em lote
- **Redu√ß√£o de 50%** no uso de API IA (devido ao cache)

### Monitoramento
- **Response time < 2s** para 95% das requisi√ß√µes
- **Error rate < 1%** em produ√ß√£o
- **Uptime > 99.5%** dos servi√ßos cr√≠ticos

## üö® Troubleshooting

### Problemas Comuns

#### PostgreSQL n√£o conecta
```bash
# Verificar se o servi√ßo est√° rodando
docker-compose logs postgres

# Testar conex√£o manual
psql -h localhost -U beecatalog_user -d beecatalog
```

#### Redis n√£o conecta
```bash
# Verificar Redis
docker-compose logs redis

# Testar conex√£o
redis-cli ping
```

#### Celery workers n√£o processam
```bash
# Verificar filas
celery -A backbeecatalog inspect active_queues

# Verificar workers ativos
celery -A backbeecatalog inspect active
```

#### Cache n√£o funciona
```python
# Verificar configura√ß√£o Redis
from django.core.cache import cache
cache.set('test', 'value', 30)
print(cache.get('test'))  # Deve retornar 'value'
```

---

**üéâ Parab√©ns! Seu BeeCatalog agora est√° otimizado para alta performance e escalabilidade!**

Para suporte adicional, consulte os logs estruturados em `/var/log/beecatalog/` ou monitore via Grafana.